{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from skimage import io\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from dataset_preparing import get_coords_from_densifing_points, generate_heatmap\n",
    "# dense에 대한 간격이나 표준편차를 하이퍼 파라미터로 조정가능한 코드. 히트맵 생성 때문에 속도는 좀 걸릴 수 있음\n",
    "# Inria 데이터 크기 조정하여 coco 포맷으로 맞춰준 데이터 처리가능\n",
    "\n",
    "def min_max_normalize(image, percentile, nodata=-1.):\n",
    "    image = image.astype('float32')\n",
    "    mask = np.mean(image, axis=2) != nodata * image.shape[2]\n",
    "\n",
    "    percent_min = np.percentile(image, percentile, axis=(0, 1))\n",
    "    percent_max = np.percentile(image, 100-percentile, axis=(0, 1))\n",
    "\n",
    "    if image.shape[1] * image.shape[0] - np.sum(mask) > 0:\n",
    "        mdata = np.ma.masked_equal(image, nodata, copy=False)\n",
    "        mdata = np.ma.filled(mdata, np.nan)\n",
    "        percent_min = np.nanpercentile(mdata, percentile, axis=(0, 1))\n",
    "\n",
    "    norm = (image-percent_min) / (percent_max - percent_min)\n",
    "    norm[norm < 0] = 0\n",
    "    norm[norm > 1] = 1\n",
    "    norm = (norm * 255).astype('uint8') * mask[:, :, np.newaxis]\n",
    "\n",
    "    return norm\n",
    "\n",
    "\n",
    "def image_graph_collate_road_network_coco(batch):\n",
    "    images = torch.stack([item['image'] for item in batch], 0).contiguous()\n",
    "    heatmap = torch.stack([item['heatmap'] for item in batch], 0).contiguous()\n",
    "    points = [item['nodes'] for item in batch]\n",
    "    edges = [item['edges'] for item in batch]\n",
    "\n",
    "    return [images, heatmap, points, edges]\n",
    "\n",
    "\n",
    "def create_polygon(segmentation):\n",
    "    # COCO segmentation format is [x1, y1, x2, y2, ..., xn, yn]\n",
    "    # We need to reshape it to [(x1, y1), (x2, y2), ..., (xn, yn)]\n",
    "    points = list(zip(segmentation[::2], segmentation[1::2]))\n",
    "    return Polygon(points)\n",
    "\n",
    "\n",
    "def gdf_to_nodes_and_edges(gdf):\n",
    "    nodes = []\n",
    "    for _, row in gdf.iterrows():\n",
    "        polygon = row['geometry']\n",
    "        if polygon.geom_type == 'Polygon':\n",
    "            for x, y in polygon.exterior.coords:\n",
    "                nodes.append((x, y))\n",
    "        elif polygon.geom_type == 'MultiPolygon':\n",
    "            for part in polygon:\n",
    "                for x, y in part.exterior.coords:\n",
    "                    nodes.append((x, y))\n",
    "        else:\n",
    "            raise AttributeError\n",
    "\n",
    "    # Remove duplicates if necessary\n",
    "    nodes = list(set(nodes))\n",
    "\n",
    "    # Create a DataFrame for nodes with unique indices\n",
    "    node_df = pd.DataFrame(nodes, columns=['x', 'y'])\n",
    "    node_df['node_id'] = range(len(node_df))\n",
    "\n",
    "    edges = []\n",
    "    for _, row in gdf.iterrows():\n",
    "        polygon = row['geometry']\n",
    "        if polygon.geom_type == 'Polygon':\n",
    "            coords = polygon.exterior.coords[:-1]  # Exclude closing vertex\n",
    "            edge = [(node_df[(node_df['x'] == x) & (node_df['y'] == y)].index[0], \n",
    "                    node_df[(node_df['x'] == coords[(i+1)%len(coords)][0]) & (node_df['y'] == coords[(i+1)%len(coords)][1])].index[0]) \n",
    "                    for i, (x, y) in enumerate(coords)]\n",
    "            edges.extend(edge)\n",
    "        elif polygon.geom_type == 'MultiPolygon':\n",
    "            for part in polygon:\n",
    "                coords = part.exterior.coords[:-1]\n",
    "                edge = [(node_df[(node_df['x'] == x) & (node_df['y'] == y)].index[0], \n",
    "                        node_df[(node_df['x'] == coords[(i+1)%len(coords)][0]) & (node_df['y'] == coords[(i+1)%len(coords)][1])].index[0]) \n",
    "                        for i, (x, y) in enumerate(coords)]\n",
    "                edges.extend(edge)\n",
    "\n",
    "    return node_df[['y', 'x']].values, edges\n",
    "\n",
    "\n",
    "class CrowdAI(Dataset):\n",
    "    \"\"\"A dataset class for handling and processing data from the CrowdAI dataset.\n",
    "\n",
    "    Attributes:\n",
    "        IMAGES_DIRECTORY (str): Directory containing the images.\n",
    "        ANNOTATIONS_PATH (str): File path for the annotations.\n",
    "        coco (COCO): COCO object to handle COCO annotations.\n",
    "        max_points (int): Maximum number of points to consider (default 256).\n",
    "        gap_distance (float): Distance between interpolated points.\n",
    "        sigma (float): Standard deviation for Gaussian kernel used in heatmap generation.\n",
    "\n",
    "    Args:\n",
    "        images_directory (str): Directory where the dataset images are stored.\n",
    "        annotations_path (str): File path for the COCO format annotations.\n",
    "        gap_distance (int, optional): Gap distance for densifying points. Defaults to 20.\n",
    "        sigma (float, optional): Sigma value for Gaussian blur in heatmap. Defaults to 1.5.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 images_directory, \n",
    "                 annotations_path,\n",
    "                 gap_datance=20,\n",
    "                 sigma=1.5):\n",
    "\n",
    "        self.IMAGES_DIRECTORY = images_directory\n",
    "        self.ANNOTATIONS_PATH = annotations_path\n",
    "        self.coco = COCO(self.ANNOTATIONS_PATH)\n",
    "        self.image_ids = self.coco.getImgIds(catIds=self.coco.getCatIds())\n",
    "\n",
    "        self.len = len(self.image_ids)\n",
    "\n",
    "        self.max_points = 256 # TODO: It should be restricted the number when gt points over the max points limit\n",
    "        self.gap_distance = gap_datance\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def prepare_annotations(self, img):\n",
    "        \"\"\"Prepares annotations for an image.\n",
    "        Args:\n",
    "            img (dict): A dictionary containing image metadata.\n",
    "\n",
    "        Returns:\n",
    "            GeoDataFrame: A GeoDataFrame containing the geometrical data of annotations.\n",
    "        \"\"\"\n",
    "        annotation_ids = self.coco.getAnnIds(imgIds=img['id'])\n",
    "        annotations = self.coco.loadAnns(annotation_ids)\n",
    "        random.shuffle(annotations)\n",
    "\n",
    "        data = []\n",
    "        for ann in annotations:\n",
    "            polygon = create_polygon(ann['segmentation'][0])\n",
    "            data.append({'id': ann['id'], 'geometry': polygon})\n",
    "        gdf = gpd.GeoDataFrame(data, geometry='geometry')\n",
    "        return gdf\n",
    "\n",
    "    def loadSample(self, idx):\n",
    "        \"\"\"Loads a sample for a given index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the sample to load.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the sample data.\n",
    "                'image' (torch.Tensor of shape [3, H, W], torch.float32): \n",
    "                    The image tensor normalized to [0, 1].\n",
    "                'image_idx' (torch.Tensor of shape [1], torch.long): \n",
    "                    The index of the image.\n",
    "                'heatmap' (torch.Tensor of shape [H, W], torch.float32): \n",
    "                    The heatmap tensor for the image normalized to [0, 1]. \n",
    "                'nodes' (torch.Tensor of shape [N, 2], torch.float): \n",
    "                    The nodes tensor representing points in the image.\n",
    "                    nodes are normalized to [0, 1]\n",
    "                'edges' (torch.Tensor of shape [E, 2], torch.long): \n",
    "                    The edges tensor representing connections between nodes.\n",
    "        \"\"\"\n",
    "        idx = self.image_ids[idx]\n",
    "\n",
    "        img = self.coco.loadImgs(idx)[0]\n",
    "        image_path = os.path.join(self.IMAGES_DIRECTORY, img['file_name'])\n",
    "        image = io.imread(image_path)\n",
    "\n",
    "        gdf = self.prepare_annotations(img)\n",
    "        coords, gdf = get_coords_from_densifing_points(gdf, gap_distance=self.gap_distance) # [N, 2]\n",
    "        heatmap = generate_heatmap(coords, image.shape[:2], sigma=self.sigma)\n",
    "\n",
    "        nodes, edges = gdf_to_nodes_and_edges(gdf)\n",
    "        nodes = nodes / image.shape[0]\n",
    "\n",
    "        image_idx = torch.tensor([idx])\n",
    "        image = torch.from_numpy(image)\n",
    "        image = image.permute(2,0,1) / 255.0\n",
    "        heatmap = torch.from_numpy(heatmap) / 255.0\n",
    "        \n",
    "        nodes = torch.tensor(nodes, dtype=torch.float)\n",
    "        edges = torch.tensor(edges, dtype=torch.long)\n",
    "\n",
    "        sample = {\n",
    "            'image': image, \n",
    "            'image_idx': image_idx, \n",
    "            'heatmap': heatmap,\n",
    "            'nodes': nodes,\n",
    "            'edges': edges\n",
    "            }\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.loadSample(idx)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CrowdAI(images_directory='/nas/tsgil/dataset/Inria_building/cocostyle/images',\n",
    "                    annotations_path='/nas/tsgil/dataset/Inria_building/cocostyle/annotation.json')\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=6, collate_fn=image_graph_collate_road_network_coco)\n",
    "\n",
    "print(next(iter(dataloader))[0].shape) # image\n",
    "\n",
    "data = next(iter(dataloader))\n",
    "\n",
    "image = data[0][1].detach().cpu().numpy().transpose(1,2,0)\n",
    "heatmap =  data[1][1].detach().cpu().numpy()\n",
    "nodes = data[2][1].detach().cpu().numpy() * image.shape[0]\n",
    "edges = data[3][1].detach().cpu().numpy()\n",
    "\n",
    "nodes = nodes.astype('int64')\n",
    "\n",
    "# Visualize\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(min_max_normalize(image, 0))\n",
    "plt.scatter(nodes[:,1], nodes[:,0], color='r')\n",
    "\n",
    "for e in edges:\n",
    "    connect = np.stack([nodes[e[0]], nodes[e[1]]], axis=0)\n",
    "    plt.plot(connect[:,1], connect[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임의의 사각형 N 타겟 노드와 엣지 리턴 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_directed_adjacency_matrix(pairs_list):\n",
    "    \"\"\" 주어진 노드 쌍 리스트를 기반으로 방향성 인접 행렬을 생성합니다. \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # 인접 행렬 크기 계산 (최대 노드 인덱스 + 1)\n",
    "    max_index = max(max(pair) for pair in pairs_list)\n",
    "    adjacency_matrix = np.zeros((max_index + 1, max_index + 1), dtype=int)\n",
    "\n",
    "    # 인접 행렬 채우기\n",
    "    for i, j in pairs_list:\n",
    "        adjacency_matrix[i, j] = 1  # 방향성 그래프: i에서 j로의 방향\n",
    "\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from dataset_preparing import get_coords_from_densifing_points\n",
    "from dataloader_cocostyle import gdf_to_nodes_and_edges\n",
    "\n",
    "# shapes and dtypes of nodes/edges are exactly same as what I defined in InriaDataLoader\n",
    "\n",
    "original_polygon = Polygon([(0, 0), (100, 0), (100, 100), (0, 100)])\n",
    "# original_polygon = Polygon([(10, 10), (90, 10), (90, 90), (10, 90)])\n",
    "gdf = gpd.GeoDataFrame(geometry = [original_polygon])\n",
    "\n",
    "coords, gdf = get_coords_from_densifing_points(gdf, gap_distance=25)\n",
    "nodes, edges = gdf_to_nodes_and_edges(gdf)\n",
    "nodes = nodes / 100\n",
    "\n",
    "nodes = nodes.astype('float32')\n",
    "edges = np.array(edges).astype('int64')\n",
    "\n",
    "\n",
    "# Visualizer\n",
    "plt.scatter(nodes[:,1], nodes[:,0])\n",
    "for e in edges:\n",
    "    plt.plot(nodes[e,1], nodes[e,0])\n",
    "\n",
    "plt.show()\n",
    "generate_directed_adjacency_matrix(edges)\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.DGS import HungarianMatcher\n",
    "import torch\n",
    "\n",
    "N = len(nodes)\n",
    "K = 50\n",
    "\n",
    "matcher = HungarianMatcher()\n",
    "matcher.eval()\n",
    "output = { # K개의 샘플링 뽑는 걸로 수정하기\n",
    "    \"pred_nodes\": torch.rand(1, K, 2),\n",
    "    } # x_cord, y_cord\n",
    "target = {'nodes':[torch.tensor(nodes)]}\n",
    "out = matcher(output, target)\n",
    "print(out[0][0])\n",
    "print(out[0][1])\n",
    "mapping = {j:i for i,j in zip(out[0][0].tolist(),out[0][1].tolist())}\n",
    "print(mapping)\n",
    "gt = [nodes[node] for node in out[0][1]]\n",
    "sample = output['pred_nodes'][0]\n",
    "print(gt)\n",
    "print(sample)\n",
    "print(nodes[0],nodes[9])\n",
    "print(edges)\n",
    "plt.scatter(sample[:,1], sample[:,0])\n",
    "if K<N:\n",
    "    mapping2 = {edge[0]: edge[1] for edge in edges}\n",
    "    sample_edge = []\n",
    "    for i, j in edges:\n",
    "        if i not in mapping:\n",
    "            while i not in mapping:\n",
    "                i = mapping2[i]\n",
    "        if j not in mapping:\n",
    "            while j not in mapping:\n",
    "                j = mapping2[j]\n",
    "        if mapping[i] != mapping[j]:\n",
    "            sample_edge.append([mapping[i],mapping[j]])\n",
    "else:\n",
    "    sample_edge = [[mapping[i],mapping[j]] for i, j in edges]\n",
    "for e in sample_edge:\n",
    "    plt.plot(sample[e,1], sample[e,0])\n",
    "plt.show()\n",
    "print(generate_directed_adjacency_matrix(sample_edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 간단한 모델 파라미터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Example model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 20), # 10->20, 파라미터 20*10개\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10) # 20->10, 파라미터 10*20개\n",
    ")\n",
    "\n",
    "# Print the weights of the first linear layer\n",
    "for name, param in model.named_parameters():\n",
    "    if name == '0.weight':  # '0' refers to the first layer\n",
    "        print(param)\n",
    "a = model.state_dict()\n",
    "print(a.keys())\n",
    "a['2.weight'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TopDiG 모델 파라미터와 ckp 파일 파라미터 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import json\n",
    "from models.TopDiG import build_TopDiG\n",
    "from models.backbone_R2U_Net import build_backbone\n",
    "class obj:\n",
    "    def __init__(self, dict1):\n",
    "        self.__dict__.update(dict1)\n",
    "def dict2obj(dict1):\n",
    "    return json.loads(json.dumps(dict1), object_hook=obj)\n",
    "\n",
    "cp_TopDiG = torch.load('/nas/tsgil/relationformer/work_dirs/TopDiG_train/runs/baseline_TopDiG_train_epoch8_10/models/epochs_8.pth', map_location='cpu')\n",
    "cp_backbone = torch.load('/nas/tsgil/relationformer/work_dirs/R2U_Net_pretrain/runs/baseline_R2U_Net_pretrain_epoch200_5e-6_10/models/epochs_130.pth', map_location='cpu')\n",
    "with open('/nas/tsgil/relationformer/configs/TopDiG_train.yaml') as f:\n",
    "    config1 = yaml.load(f, Loader=yaml.FullLoader)\n",
    "config1 = dict2obj(config1)\n",
    "with open('/nas/tsgil/relationformer/configs/inria_pretrain.yaml') as f:\n",
    "    config2 = yaml.load(f, Loader=yaml.FullLoader)\n",
    "config2 = dict2obj(config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cp_backbone.keys())\n",
    "print(cp_backbone['model_state_dict'].keys())\n",
    "# print(cp_backbone['model_state_dict']['encoder.RRCNN1.RCNN.0.conv.0.weight'])\n",
    "\n",
    "model1 = build_TopDiG(config1)\n",
    "model2 = build_backbone(config2)\n",
    "\n",
    "model1_dict = model1.state_dict()\n",
    "model1_backbone_dict = model1.backbone.state_dict()\n",
    "print(model1_dict.keys())\n",
    "print(model1_backbone_dict.keys())\n",
    "total_params = sum(p.numel() for p in model1.backbone.parameters())\n",
    "print(total_params)\n",
    "\n",
    "model2_dict = model2.state_dict()\n",
    "print(model2_dict.keys())\n",
    "model2.load_state_dict(cp_backbone['model_state_dict']) # , strict=False\n",
    "total_params = sum(p.numel() for p in model2.parameters())\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model1_dict.keys()), model1_dict.keys())\n",
    "print(len(model2_dict.keys()), model2_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.equal(model1_backbone_dict['encoder.RRCNN1.RCNN.0.conv.0.weight'], model2_dict['encoder.RRCNN1.RCNN.0.conv.0.weight']):\n",
    "    print('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_name_keywords(name, name_keywords):\n",
    "    for keyword in name_keywords:\n",
    "        if keyword == name.split('.')[0]:\n",
    "            return True\n",
    "    else: return False\n",
    "\n",
    "cnt = 0\n",
    "for n, p in model2.named_parameters():\n",
    "    if match_name_keywords(n, ['encoder']):\n",
    "        cnt += 1\n",
    "print(cnt)\n",
    "cnt = 0\n",
    "for i in model2.parameters():\n",
    "    cnt += 1\n",
    "print(cnt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
