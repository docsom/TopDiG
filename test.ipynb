{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from skimage import io\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from dataset_preparing import get_coords_from_densifing_points, generate_heatmap\n",
    "# dense에 대한 간격이나 표준편차를 하이퍼 파라미터로 조정가능한 코드. 히트맵 생성 때문에 속도는 좀 걸릴 수 있음\n",
    "# Inria 데이터 크기 조정하여 coco 포맷으로 맞춰준 데이터 처리가능\n",
    "\n",
    "def min_max_normalize(image, percentile, nodata=-1.):\n",
    "    image = image.astype('float32')\n",
    "    mask = np.mean(image, axis=2) != nodata * image.shape[2]\n",
    "\n",
    "    percent_min = np.percentile(image, percentile, axis=(0, 1))\n",
    "    percent_max = np.percentile(image, 100-percentile, axis=(0, 1))\n",
    "\n",
    "    if image.shape[1] * image.shape[0] - np.sum(mask) > 0:\n",
    "        mdata = np.ma.masked_equal(image, nodata, copy=False)\n",
    "        mdata = np.ma.filled(mdata, np.nan)\n",
    "        percent_min = np.nanpercentile(mdata, percentile, axis=(0, 1))\n",
    "\n",
    "    norm = (image-percent_min) / (percent_max - percent_min)\n",
    "    norm[norm < 0] = 0\n",
    "    norm[norm > 1] = 1\n",
    "    norm = (norm * 255).astype('uint8') * mask[:, :, np.newaxis]\n",
    "\n",
    "    return norm\n",
    "\n",
    "\n",
    "def image_graph_collate_road_network_coco(batch):\n",
    "    images = torch.stack([item['image'] for item in batch], 0).contiguous()\n",
    "    heatmap = torch.stack([item['heatmap'] for item in batch], 0).contiguous()\n",
    "    points = [item['nodes'] for item in batch]\n",
    "    edges = [item['edges'] for item in batch]\n",
    "\n",
    "    return [images, heatmap, points, edges]\n",
    "\n",
    "\n",
    "def create_polygon(segmentation):\n",
    "    # COCO segmentation format is [x1, y1, x2, y2, ..., xn, yn]\n",
    "    # We need to reshape it to [(x1, y1), (x2, y2), ..., (xn, yn)]\n",
    "    points = list(zip(segmentation[::2], segmentation[1::2]))\n",
    "    return Polygon(points)\n",
    "\n",
    "\n",
    "def gdf_to_nodes_and_edges(gdf):\n",
    "    nodes = []\n",
    "    for _, row in gdf.iterrows():\n",
    "        polygon = row['geometry']\n",
    "        if polygon.geom_type == 'Polygon':\n",
    "            for x, y in polygon.exterior.coords:\n",
    "                nodes.append((x, y))\n",
    "        elif polygon.geom_type == 'MultiPolygon':\n",
    "            for part in polygon:\n",
    "                for x, y in part.exterior.coords:\n",
    "                    nodes.append((x, y))\n",
    "        else:\n",
    "            raise AttributeError\n",
    "\n",
    "    # Remove duplicates if necessary\n",
    "    nodes = list(set(nodes))\n",
    "\n",
    "    # Create a DataFrame for nodes with unique indices\n",
    "    node_df = pd.DataFrame(nodes, columns=['x', 'y'])\n",
    "    node_df['node_id'] = range(len(node_df))\n",
    "\n",
    "    edges = []\n",
    "    for _, row in gdf.iterrows():\n",
    "        polygon = row['geometry']\n",
    "        if polygon.geom_type == 'Polygon':\n",
    "            coords = polygon.exterior.coords[:-1]  # Exclude closing vertex\n",
    "            edge = [(node_df[(node_df['x'] == x) & (node_df['y'] == y)].index[0], \n",
    "                    node_df[(node_df['x'] == coords[(i+1)%len(coords)][0]) & (node_df['y'] == coords[(i+1)%len(coords)][1])].index[0]) \n",
    "                    for i, (x, y) in enumerate(coords)]\n",
    "            edges.extend(edge)\n",
    "        elif polygon.geom_type == 'MultiPolygon':\n",
    "            for part in polygon:\n",
    "                coords = part.exterior.coords[:-1]\n",
    "                edge = [(node_df[(node_df['x'] == x) & (node_df['y'] == y)].index[0], \n",
    "                        node_df[(node_df['x'] == coords[(i+1)%len(coords)][0]) & (node_df['y'] == coords[(i+1)%len(coords)][1])].index[0]) \n",
    "                        for i, (x, y) in enumerate(coords)]\n",
    "                edges.extend(edge)\n",
    "\n",
    "    return node_df[['y', 'x']].values, edges\n",
    "\n",
    "\n",
    "class CrowdAI(Dataset):\n",
    "    \"\"\"A dataset class for handling and processing data from the CrowdAI dataset.\n",
    "\n",
    "    Attributes:\n",
    "        IMAGES_DIRECTORY (str): Directory containing the images.\n",
    "        ANNOTATIONS_PATH (str): File path for the annotations.\n",
    "        coco (COCO): COCO object to handle COCO annotations.\n",
    "        max_points (int): Maximum number of points to consider (default 256).\n",
    "        gap_distance (float): Distance between interpolated points.\n",
    "        sigma (float): Standard deviation for Gaussian kernel used in heatmap generation.\n",
    "\n",
    "    Args:\n",
    "        images_directory (str): Directory where the dataset images are stored.\n",
    "        annotations_path (str): File path for the COCO format annotations.\n",
    "        gap_distance (int, optional): Gap distance for densifying points. Defaults to 20.\n",
    "        sigma (float, optional): Sigma value for Gaussian blur in heatmap. Defaults to 1.5.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 images_directory, \n",
    "                 annotations_path,\n",
    "                 gap_datance=20,\n",
    "                 sigma=1.5):\n",
    "\n",
    "        self.IMAGES_DIRECTORY = images_directory\n",
    "        self.ANNOTATIONS_PATH = annotations_path\n",
    "        self.coco = COCO(self.ANNOTATIONS_PATH)\n",
    "        self.image_ids = self.coco.getImgIds(catIds=self.coco.getCatIds())\n",
    "\n",
    "        self.len = len(self.image_ids)\n",
    "\n",
    "        self.max_points = 256 # TODO: It should be restricted the number when gt points over the max points limit\n",
    "        self.gap_distance = gap_datance\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def prepare_annotations(self, img):\n",
    "        \"\"\"Prepares annotations for an image.\n",
    "        Args:\n",
    "            img (dict): A dictionary containing image metadata.\n",
    "\n",
    "        Returns:\n",
    "            GeoDataFrame: A GeoDataFrame containing the geometrical data of annotations.\n",
    "        \"\"\"\n",
    "        annotation_ids = self.coco.getAnnIds(imgIds=img['id'])\n",
    "        annotations = self.coco.loadAnns(annotation_ids)\n",
    "        random.shuffle(annotations)\n",
    "\n",
    "        data = []\n",
    "        for ann in annotations:\n",
    "            polygon = create_polygon(ann['segmentation'][0])\n",
    "            data.append({'id': ann['id'], 'geometry': polygon})\n",
    "        gdf = gpd.GeoDataFrame(data, geometry='geometry')\n",
    "        return gdf\n",
    "\n",
    "    def loadSample(self, idx):\n",
    "        \"\"\"Loads a sample for a given index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the sample to load.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the sample data.\n",
    "                'image' (torch.Tensor of shape [3, H, W], torch.float32): \n",
    "                    The image tensor normalized to [0, 1].\n",
    "                'image_idx' (torch.Tensor of shape [1], torch.long): \n",
    "                    The index of the image.\n",
    "                'heatmap' (torch.Tensor of shape [H, W], torch.float32): \n",
    "                    The heatmap tensor for the image normalized to [0, 1]. \n",
    "                'nodes' (torch.Tensor of shape [N, 2], torch.float): \n",
    "                    The nodes tensor representing points in the image.\n",
    "                    nodes are normalized to [0, 1]\n",
    "                'edges' (torch.Tensor of shape [E, 2], torch.long): \n",
    "                    The edges tensor representing connections between nodes.\n",
    "        \"\"\"\n",
    "        idx = self.image_ids[idx]\n",
    "\n",
    "        img = self.coco.loadImgs(idx)[0]\n",
    "        image_path = os.path.join(self.IMAGES_DIRECTORY, img['file_name'])\n",
    "        image = io.imread(image_path)\n",
    "\n",
    "        gdf = self.prepare_annotations(img)\n",
    "        coords, gdf = get_coords_from_densifing_points(gdf, gap_distance=self.gap_distance) # [N, 2]\n",
    "        heatmap = generate_heatmap(coords, image.shape[:2], sigma=self.sigma)\n",
    "\n",
    "        nodes, edges = gdf_to_nodes_and_edges(gdf)\n",
    "        nodes = nodes / image.shape[0]\n",
    "\n",
    "        image_idx = torch.tensor([idx])\n",
    "        image = torch.from_numpy(image)\n",
    "        image = image.permute(2,0,1) / 255.0\n",
    "        heatmap = torch.from_numpy(heatmap) / 255.0\n",
    "        \n",
    "        nodes = torch.tensor(nodes, dtype=torch.float)\n",
    "        edges = torch.tensor(edges, dtype=torch.long)\n",
    "\n",
    "        sample = {\n",
    "            'image': image, \n",
    "            'image_idx': image_idx, \n",
    "            'heatmap': heatmap,\n",
    "            'nodes': nodes,\n",
    "            'edges': edges\n",
    "            }\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.loadSample(idx)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CrowdAI(images_directory='/nas/tsgil/dataset/Inria_building/cocostyle/images',\n",
    "                    annotations_path='/nas/tsgil/dataset/Inria_building/cocostyle/annotation.json')\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=6, collate_fn=image_graph_collate_road_network_coco)\n",
    "\n",
    "print(next(iter(dataloader))[0].shape) # image\n",
    "\n",
    "data = next(iter(dataloader))\n",
    "\n",
    "image = data[0][1].detach().cpu().numpy().transpose(1,2,0)\n",
    "heatmap =  data[1][1].detach().cpu().numpy()\n",
    "nodes = data[2][1].detach().cpu().numpy() * image.shape[0]\n",
    "edges = data[3][1].detach().cpu().numpy()\n",
    "\n",
    "nodes = nodes.astype('int64')\n",
    "\n",
    "# Visualize\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(min_max_normalize(image, 0))\n",
    "plt.scatter(nodes[:,1], nodes[:,0], color='r')\n",
    "\n",
    "for e in edges:\n",
    "    connect = np.stack([nodes[e[0]], nodes[e[1]]], axis=0)\n",
    "    plt.plot(connect[:,1], connect[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임의의 사각형 N 타겟 노드와 엣지 리턴 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_directed_adjacency_matrix(pairs_list):\n",
    "    \"\"\" 주어진 노드 쌍 리스트를 기반으로 방향성 인접 행렬을 생성합니다. \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # 인접 행렬 크기 계산 (최대 노드 인덱스 + 1)\n",
    "    max_index = max(max(pair) for pair in pairs_list)\n",
    "    adjacency_matrix = np.zeros((max_index + 1, max_index + 1), dtype=int)\n",
    "\n",
    "    # 인접 행렬 채우기\n",
    "    for i, j in pairs_list:\n",
    "        adjacency_matrix[i, j] = 1  # 방향성 그래프: i에서 j로의 방향\n",
    "\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoPklEQVR4nO3df3TU1Z3/8ddMQmbgmAxizCRg2gAtIkVhAZNGxR/dtHjsSZc9Z7dUKj/yVVwRepSc3QLyI6CWoFXKWRvhiGI8qy5Uv+q3Fr6xGo2uNWu6CfkeKYiHJgitmSCbNRMD+cHM/f4RMmQggUxI5maS5+Oc0Zk79zPzzr2ZuS8+n/lkHMYYIwAAAEuctgsAAADDG2EEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFXxtgvojWAwqC+++EKJiYlyOBy2ywEAAL1gjFFTU5PGjh0rp7Pn/R8xEUa++OILpaen2y4DAAD0wbFjx3TVVVf1eH9MhJHExERJHT9MUlKS5WoAAEBv+P1+paenh9bxnsREGOk8NJOUlEQYAQAgxlzsIxZ8gBUAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgVUz80bOBEAgaVdQ26HhTi1IS3cocP0ZxTr73JpYwh7GPOYxtzF/sGyxzGHEY+eCDD/TLX/5SlZWVqqur0+uvv665c+decJuysjLl5+frT3/6k9LT07V27VotXry4jyVfupL9ddr45gHVNbaE2tI8bhXkTtHtU9Os1YXeYw5jH3MY25i/2DeY5jDiwzTNzc2aNm2aioqKetW/trZWP/zhD3XbbbepurpaDz74oO655x699dZbERfbH0r212npi1Vhgy9JvsYWLX2xSiX766zUhd5jDmMfcxjbmL/YN9jm0GGMMX3e2OG46J6RlStXas+ePdq/f3+o7Sc/+Ym++uorlZSU9Op5/H6/PB6PGhsbL+m7aQJBo5see/fM4Ac10vF1xx1mhCSHHJK8SW69k38LuxoHqUDQKGfL+/L5w19Ap+SS1DFn3iQXcziIdc5hvb9VRgr/J5Gj83XYMYdO5nDQCYZeg62SjBKcbWfuMHJIvI/GgPD3UaN4BSVJJwNuSU45JKV63Ppw5fcueQ57u34P+GdGysvLlZOTE9Y2Z84cPfjggz1u09raqtbW1tBtv9/fL7VU1DaEUuBIx9eKn7xJkvTxkWMa1ZnJ2iRt7penwwCIk/SeJLnD269p2alTZxrr/a26dsPvo10a+sAh6cz7oFr+Nk2K70gmn0v69of7e9oMtmVeEbra+U79nJkvt86+b//Hf0S5JkSk4Prz235WulknA6NkJNU1tqiitkHZE684v+MAGPCzaXw+n7xeb1ib1+uV3+/XqVOnut2msLBQHo8ndElPT++XWo43tVy8EwAAiOqaOSjPplm9erXy8/NDt/1+f78EkpTEs/+cPiWXEs9cn9myTTIJofuKF2cqa8KYS34+9L+Paxq0uLjivPaOwzRnPb/4euZwkPq4pkF5xX+UpLDDNK736qQuXzNevPh6ZTKHg05FTYMWn5m/rodpHgw+qq479HkfHby6vo/GK6CfuKolSW2BhLB+XdfMgTbgYSQ1NVX19fVhbfX19UpKStLIkSO73cblcsnlcnV736XIHD9GaR63fI0tMl1eNh279xNCx8lmTbpK4ljnoDRr0iiN9nx2Zg7P1zmHN0+6kuPVg9TNk64MvQ4lhQ7TdDBn53BiMnM4CN08MVljL3OFXoPt5yxgnfOXNXEc8zdIZU0cqSsu88jX2KKgAgoGR5y5xxH6b6qn4zTfaBnwwzTZ2dkqLS0Na3v77beVnZ090E99njinQwW5UyRJ575EOm8X5E7hBTSIMYexjzmMbcxf7BuMcxhxGPn6669VXV2t6upqSR2n7lZXV+vo0aOSOg6xLFy4MNT/vvvuU01NjX7+85/r008/1dNPP63f/OY3WrFiRf/8BBG6fWqatt01Q15P+J6XVI9b2+6awfnxMaBzDlM94bsQmcPYwRzGNuYv9oXWwqTBMYcRn9pbVlam22677bz2RYsWqbi4WIsXL9aRI0dUVlYWts2KFSt04MABXXXVVVq3bl1Ef/Ssv07t7err1mZl7/quJOmp7P+r2d9il2KsGSx/ORB9xxzGNuYv9p1qadVjmwslSX/7k/t0wyRvv87hgJ3ae+utt+pC+aW4uLjbbfbt2xfpUw2orn+/gBdQbIpzOqJ22hkGBnMY25i/2Nd17cuaYG8t5IvyAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFV9CiNFRUXKyMiQ2+1WVlaWKioqLth/69atuvrqqzVy5Eilp6drxYoVamlp6VPBAABgaIk4jOzevVv5+fkqKChQVVWVpk2bpjlz5uj48ePd9n/55Ze1atUqFRQU6ODBg3ruuee0e/duPfTQQ5dcPAAAiH0Rh5EtW7ZoyZIlysvL05QpU7R9+3aNGjVKO3fu7Lb/Rx99pBtvvFHz589XRkaGfvCDH+jOO++86N4UAAAwPEQURtra2lRZWamcnJyzD+B0KicnR+Xl5d1uc8MNN6iysjIUPmpqarR3717dcccdPT5Pa2ur/H5/2AUAAAxN8ZF0PnHihAKBgLxeb1i71+vVp59+2u028+fP14kTJ3TTTTfJGKPTp0/rvvvuu+BhmsLCQm3cuDGS0gAAQIwa8LNpysrKtGnTJj399NOqqqrSa6+9pj179uiRRx7pcZvVq1ersbExdDl27NhAlwkAACyJaM9IcnKy4uLiVF9fH9ZeX1+v1NTUbrdZt26dFixYoHvuuUeSdO2116q5uVn33nuv1qxZI6fz/DzkcrnkcrkiKQ0AAMSoiPaMJCQkaObMmSotLQ21BYNBlZaWKjs7u9ttTp48eV7giIuLkyQZYyKtFwAADDER7RmRpPz8fC1atEizZs1SZmamtm7dqubmZuXl5UmSFi5cqHHjxqmwsFCSlJubqy1btuhv/uZvlJWVpcOHD2vdunXKzc0NhRIAADB8RRxG5s2bpy+//FLr16+Xz+fT9OnTVVJSEvpQ69GjR8P2hKxdu1YOh0Nr167VX//6V1155ZXKzc3VL37xi/77KQAAQMxymBg4VuL3++XxeNTY2KikpKR+ecyT7SeV9XKWJOnj+R9r1IhR/fK4AADEira2Nm3atEmS9NBDDykhIaFfH7+36zffTQMAAKwijAAAAKsIIwAAwCrCCAAAsGrYhpFg8OznditqGxQIDvrP8QIA0K+6rn0f19hbC4dlGCnZX6ecX70fur34+T/qpsfeVcn+OotVAQAQPSX76/T9LWfXwrziCmtr4bALIyX767T0xSr5GlvD2n2NLVr6YhWBBAAw5IXWQn9LWLuttXBYhZFA0GjjmwdkJMkYudo6LjJGnTumNr55gEM2AIAhK2wtPIettXBYhZGK2gbVNXakQFegXf/2ZED/9mRArkC7pI5JqGtsUUVtg8UqAQAYOGFrYZf2zus21sJhFUaON7VcvFME/QAAiDWDcS2M+LtpYllKovvsDTOi++vn9gMAYAjpusYF5NSillslSbv0dY/9Btqw2jOSOX6M0jxuOXq43yEpzeNW5vgx0SwLAICoCV8LHRqhOI1QnBRqif5aOKzCSJzToYLcKZJ0XiDpvF2QO0Vxzp7iCgAAsW0wroXDKoxI0u1T07TtrhnyJoXvfkr1uLXtrhm6fWqapcoAAIiOwbYWOowxg/481t5+BXEk2r9u1uFZsyRJX/3vt5V5zTj2iAAAhpX2ltOq31AuSfrL4sm6flJyv66FvV2/h9UHWLvqOthZ48fISRABAAwzXdfCzAn21sJhd5gGAAAMLoQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABW9SmMFBUVKSMjQ263W1lZWaqoqLhg/6+++krLli1TWlqaXC6XJk2apL179/apYAAAMLTER7rB7t27lZ+fr+3btysrK0tbt27VnDlzdOjQIaWkpJzXv62tTd///veVkpKiV199VePGjdPnn3+u0aNH90f9AAAgxkUcRrZs2aIlS5YoLy9PkrR9+3bt2bNHO3fu1KpVq87rv3PnTjU0NOijjz7SiBEjJEkZGRmXVjUAABgyIjpM09bWpsrKSuXk5Jx9AKdTOTk5Ki8v73ab3/72t8rOztayZcvk9Xo1depUbdq0SYFAoMfnaW1tld/vD7sAAIChKaIwcuLECQUCAXm93rB2r9crn8/X7TY1NTV69dVXFQgEtHfvXq1bt05PPvmkHn300R6fp7CwUB6PJ3RJT0+PpEwAABBDBvxsmmAwqJSUFD3zzDOaOXOm5s2bpzVr1mj79u09brN69Wo1NjaGLseOHRvoMgEAgCURfWYkOTlZcXFxqq+vD2uvr69Xampqt9ukpaVpxIgRiouLC7Vdc8018vl8amtrU0JCwnnbuFwuuVyuSEoDAAAxKqI9IwkJCZo5c6ZKS0tDbcFgUKWlpcrOzu52mxtvvFGHDx9WMBgMtX322WdKS0vrNogAAIDhJeLDNPn5+dqxY4deeOEFHTx4UEuXLlVzc3Po7JqFCxdq9erVof5Lly5VQ0ODHnjgAX322Wfas2ePNm3apGXLlvXfTwEAAGJWxKf2zps3T19++aXWr18vn8+n6dOnq6SkJPSh1qNHj8rpPJtx0tPT9dZbb2nFihW67rrrNG7cOD3wwANauXJl//0UAAAgZjmMMcZ2ERfj9/vl8XjU2NiopKSkfnnM4MmTOjRjpiTp6qpKOUeN6pfHBQAgVgTbAvpi/UeSpLEP3yBnQtxFtohMb9dvvpsGAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWDVsw0ggaELXP65tCLsNAMBw0HXtq6ixtxYOyzBSsr9OOVveD91e/HyFbnrsXZXsr7NYFQAA0VOyv07f77oWFttbC4ddGCnZX6elL1bJ528Ja/c1tmjpi1UEEgDAkDfY1sJhFUYCQaONbx6QkSQjBZwJCjgTJCN17pja+OYBDtkAAIas8LWwy3pnjLW1cFiFkYraBtU1dqTAeEnv3/wrvX/zrxR/5n4jqa6xRRW1DbZKBABgQIWtheZ0qL3zuo21cFiFkeNNLRfvFEE/AABizWBcC+Mv3mXoSEl0h663xSV0e/3cfgAADCVd17gWSa8e2dJx/RuLeuw30IbVnpHM8WOU5nHLIUkOx9k7zlx3SErzuJU5foyN8gAAGHBha6GkgGlXwLSH7rexFg6rMBLndKggd4okyXHOfZ23C3KnKM557r0AAAwNg3EtHFZhRJJun5qmbXfNUEpS+O6nVI9b2+6aodunplmqDACA6OhcC72DZC10GGMG/Xmsfr9fHo9HjY2NSkpK6pfHbDl1Ws+t+ECSNO2Bqcq++kr2iAAAhpWWk6dUlPePkqSsDc8o++q0fl0Le7t+D7s9I526DnbWhCsIIgCAYSdsLRw/xtpaOGzDCAAAGBwIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCqT2GkqKhIGRkZcrvdysrKUkVFRa+227VrlxwOh+bOnduXpwUAAENQxGFk9+7dys/PV0FBgaqqqjRt2jTNmTNHx48fv+B2R44c0T//8z9r9uzZfS4WAAAMPRGHkS1btmjJkiXKy8vTlClTtH37do0aNUo7d+7scZtAIKCf/vSn2rhxoyZMmHBJBQMAgKElojDS1tamyspK5eTknH0Ap1M5OTkqLy/vcbuHH35YKSkpuvvuu3v1PK2trfL7/WEXAAAwNEUURk6cOKFAICCv1xvW7vV65fP5ut3mww8/1HPPPacdO3b0+nkKCwvl8XhCl/T09EjKBAAAMWRAz6ZpamrSggULtGPHDiUnJ/d6u9WrV6uxsTF0OXbs2ABWCQAAbIqPpHNycrLi4uJUX18f1l5fX6/U1NTz+v/5z3/WkSNHlJubG2oLBoMdTxwfr0OHDmnixInnbedyueRyuSIpDQAAxKiI9owkJCRo5syZKi0tDbUFg0GVlpYqOzv7vP6TJ0/WJ598ourq6tDlRz/6kW677TZVV1dz+AUAAES2Z0SS8vPztWjRIs2aNUuZmZnaunWrmpublZeXJ0lauHChxo0bp8LCQrndbk2dOjVs+9GjR0vSee0AAGB4ijiMzJs3T19++aXWr18vn8+n6dOnq6SkJPSh1qNHj8rp5A+7AgCA3ok4jEjS8uXLtXz58m7vKysru+C2xcXFfXlKAAAwRLELAwAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVg3bMBIImtD1j2v+O+w2AADDQdhaWNtgbS0clmGkZH+dcra8H7qdV/xH3fTYuyrZX2exKgAAoufctXDx8xXW1sJhF0ZK9tdp6YtVqve3hLX7Glu09MUqAgkAYMjrXAt9g2QtHFZhJBA02vjmARlJMkbGtMuY9o7rZ/psfPMAh2wAAENW+FrY5Q4ja2vhsAojFbUNqmvsSIHx5rRav3pKrV89pXhzWlLHJNQ1tqiitsFilQAADJyua+GILu2d122shcMqjBxvarl4pwj6AQAQawbjWhgftWcaBFIS3aHr7V3a2y/QDwCAoaTrGnfaES/X6J+dud7eY7+BNqz2jGSOH6M0j1sOSR3/OcNx9n9pHrcyx4+JfnEAAERB+FrokMMxQg7HCMnRsRjaWAuHVRiJczpUkDtFUngW6Xq7IHeK4pzn3gsAwNAwGNfCYRVGJOn2qWnadtcMeZPCdz+letzadtcM3T41zVJlAABER+damDJI1kKHMWbQn8fq9/vl8XjU2NiopKSkfnnMlpOnVJT3j5KkrA3PKPvqNPaIAACGlZZTp/Xcig8kSdMemKrsq6/s17Wwt+v3sNsz0qnrYGeNH0MQAQAMO2Fr4YQrrK2FwzaMAACAwYEwAgAArCKMAAAAqwgjAADAKsIIAACwijACAACs6lMYKSoqUkZGhtxut7KyslRRUdFj3x07dmj27Nm6/PLLdfnllysnJ+eC/QEAwPAScRjZvXu38vPzVVBQoKqqKk2bNk1z5szR8ePHu+1fVlamO++8U++9957Ky8uVnp6uH/zgB/rrX/96ycUDAIDYF3EY2bJli5YsWaK8vDxNmTJF27dv16hRo7Rz585u+7/00ku6//77NX36dE2ePFnPPvusgsGgSktLL7l4AAAQ+yIKI21tbaqsrFROTs7ZB3A6lZOTo/Ly8l49xsmTJ9Xe3q4xY3r+NsDW1lb5/f6wCwAAGJoiCiMnTpxQIBCQ1+sNa/d6vfL5fL16jJUrV2rs2LFhgeZchYWF8ng8oUt6enokZQIAgBgS1bNpNm/erF27dun111+X2+3usd/q1avV2NgYuhw7diyKVQIAgGiKj6RzcnKy4uLiVF9fH9ZeX1+v1NTUC277xBNPaPPmzXrnnXd03XXXXbCvy+WSy+WKpDQAABCjItozkpCQoJkzZ4Z9+LTzw6jZ2dk9bvf444/rkUceUUlJiWbNmtX3agEAwJAT0Z4RScrPz9eiRYs0a9YsZWZmauvWrWpublZeXp4kaeHChRo3bpwKCwslSY899pjWr1+vl19+WRkZGaHPllx22WW67LLL+vFHAQAAsSjiMDJv3jx9+eWXWr9+vXw+n6ZPn66SkpLQh1qPHj0qp/PsDpdt27apra1N//AP/xD2OAUFBdqwYcOlVQ8AAGJexGFEkpYvX67ly5d3e19ZWVnY7SNHjvTlKQAAwDDBd9MAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsCredgG2BIImdP3j2gZlX52mOKfDYkWIVCBoVFHboONNLUpJdCtz/BjmMMYwh7GN+Yt9YWthzX8r++orrcxhn8JIUVGRfvnLX8rn82natGl66qmnlJmZ2WP/V155RevWrdORI0f07W9/W4899pjuuOOOPhd9qUr21+nRN/6f/v7M7cXPV+jKyxNVkDtFt09Ns1YXeq9kf502vnlAdY0tobY0j5s5jCHMYWxj/mJfyf46Pfp/DuhOdYSPvOI/Knm0nTmM+DDN7t27lZ+fr4KCAlVVVWnatGmaM2eOjh8/3m3/jz76SHfeeafuvvtu7du3T3PnztXcuXO1f//+Sy6+L0r212npi1Xy+VvC2n2NLVr6YpVK9tdZqQu91zmHXd8EJeYwljCHsY35i32dc1g/SNZChzHGXLzbWVlZWbr++uv161//WpIUDAaVnp6un/3sZ1q1atV5/efNm6fm5mb97ne/C7V997vf1fTp07V9+/ZePaff75fH41FjY6OSkpIiKTdMIGh002Pvqq6xRfHBdi39/FlJ0rZv3qPTzhGSJG+SS+/k38KuxkEqEDTK2fK+6v2tkoxGqjXsfockb5KbORzEOuew4x8ERnK0S5JOySXJ0TGHHpfeWXGLnMzhoBMMGuX86n35GlslY+QKdMyfTMd7KK/Bwa/razDeSPc3j5YkbU06qXZnx2sw1ePWhyu/d8lz2Nv1O6LDNG1tbaqsrNTq1atDbU6nUzk5OSovL+92m/LycuXn54e1zZkzR2+88UaPz9Pa2qrW1rOLjN/vj6TMHlXUNpyX5M9V72/VtRt+3y/Ph4E1Uq066P5f59/RJmlz1MtBL8VJek+S3NJJh0NZGemSpMQufZolZe+Kfm3opTQpMU1ytRn925OBbrscfjnKNSEinbsCAs4EvX/zryRJCYE2tTtdMpLqGltUUdug7IlXRKWeiA7TnDhxQoFAQF6vN6zd6/XK5/N1u43P54uovyQVFhbK4/GELunp6ZGU2aPjTRcOIgAAoEM018xBeTbN6tWrw/am+P3+fgkkKYnu0PXTjnht++Y9oetdPb/4emVNGHPJz4f+93FNg/KK/yipY7f+NS07u+1XvDiTORykPq5p0OLiijO3jPRp+GGaTsV51ytzPHM42FTUNmjx8x2vwSZjNDc3/DBNp+K8TGUxf4PSx7UNWvz8mdegkeL1lSSpOS4hrF/XNXOgRRRGkpOTFRcXp/r6+rD2+vp6paamdrtNampqRP0lyeVyyeVyRVJar2SOH6M0j1u+xhYZh0OnHeEvns7jZDdPsnNqEy7u5klXnp1DOXRK4S+WzjmcNekqiTkclGZNGqXRns/OzKEkMzLs/s45nP2tcbwOB6HZ3xqptKRDoflrjQt/r+6cv8xrxvGZn0Eq85qRGnOF5+wcnnN/aA6jGCYjOkyTkJCgmTNnqrS0NNQWDAZVWlqq7OzsbrfJzs4O6y9Jb7/9do/9B1Kc06GC3CmSuv77S2G3C3Kn8AY4iDGHsY85jG3MX+wbjHMY8am9+fn52rFjh1544QUdPHhQS5cuVXNzs/Ly8iRJCxcuDPuA6wMPPKCSkhI9+eST+vTTT7Vhwwb913/9l5YvX95/P0UEbp+apm13zVCqJ/xf1Kket7bdNYPz42MAcxj7mMPYxvzFvsE2hxGf2itJv/71r0N/9Gz69On613/9V2VlZUmSbr31VmVkZKi4uDjU/5VXXtHatWtDf/Ts8ccfj+iPnvXXqb1d8ZcDYx9zGPuYw9jG/MW+gZ7D3q7ffQoj0TYQYQQAAAys3q7ffFEeAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsCqib+21pfOPxPr9fsuVAACA3upcty/2x95jIow0NTVJktLT0y1XAgAAItXU1CSPx9Pj/THx3TTBYFBffPGFEhMT5XD07xf4pKen69ixY3znzQBinKOHsY4Oxjk6GOfoGMhxNsaoqalJY8eOldPZ8ydDYmLPiNPp1FVXXTVgj5+UlMQvehQwztHDWEcH4xwdjHN0DNQ4X2iPSCc+wAoAAKwijAAAAKuGdRhxuVwqKCiQy+WyXcqQxjhHD2MdHYxzdDDO0TEYxjkmPsAKAACGrmG9ZwQAANhHGAEAAFYRRgAAgFWEEQAAYNWQDyNFRUXKyMiQ2+1WVlaWKioqLtj/lVde0eTJk+V2u3Xttddq7969Uao0tkUyzjt27NDs2bN1+eWX6/LLL1dOTs5F5wVnRfo73WnXrl1yOByaO3fuwBY4REQ6zl999ZWWLVumtLQ0uVwuTZo0ifePXoh0nLdu3aqrr75aI0eOVHp6ulasWKGWlpYoVRubPvjgA+Xm5mrs2LFyOBx64403LrpNWVmZZsyYIZfLpW9961sqLi4e2CLNELZr1y6TkJBgdu7caf70pz+ZJUuWmNGjR5v6+vpu+//hD38wcXFx5vHHHzcHDhwwa9euNSNGjDCffPJJlCuPLZGO8/z5801RUZHZt2+fOXjwoFm8eLHxeDzmL3/5S5Qrjz2RjnWn2tpaM27cODN79mzzd3/3d9EpNoZFOs6tra1m1qxZ5o477jAffvihqa2tNWVlZaa6ujrKlceWSMf5pZdeMi6Xy7z00kumtrbWvPXWWyYtLc2sWLEiypXHlr1795o1a9aY1157zUgyr7/++gX719TUmFGjRpn8/Hxz4MAB89RTT5m4uDhTUlIyYDUO6TCSmZlpli1bFrodCATM2LFjTWFhYbf9f/zjH5sf/vCHYW1ZWVnmn/7pnwa0zlgX6Tif6/Tp0yYxMdG88MILA1XikNGXsT59+rS54YYbzLPPPmsWLVpEGOmFSMd527ZtZsKECaatrS1aJQ4JkY7zsmXLzPe+972wtvz8fHPjjTcOaJ1DSW/CyM9//nPzne98J6xt3rx5Zs6cOQNW15A9TNPW1qbKykrl5OSE2pxOp3JyclReXt7tNuXl5WH9JWnOnDk99kffxvlcJ0+eVHt7u8aMGTNQZQ4JfR3rhx9+WCkpKbr77rujUWbM68s4//a3v1V2draWLVsmr9erqVOnatOmTQoEAtEqO+b0ZZxvuOEGVVZWhg7l1NTUaO/evbrjjjuiUvNwYWMtjIkvyuuLEydOKBAIyOv1hrV7vV59+umn3W7j8/m67e/z+QaszljXl3E+18qVKzV27NjzfvkRri9j/eGHH+q5555TdXV1FCocGvoyzjU1NXr33Xf105/+VHv37tXhw4d1//33q729XQUFBdEoO+b0ZZznz5+vEydO6KabbpIxRqdPn9Z9992nhx56KBolDxs9rYV+v1+nTp3SyJEj+/05h+yeEcSGzZs3a9euXXr99dfldrttlzOkNDU1acGCBdqxY4eSk5NtlzOkBYNBpaSk6JlnntHMmTM1b948rVmzRtu3b7dd2pBSVlamTZs26emnn1ZVVZVee+017dmzR4888ojt0nCJhuyekeTkZMXFxam+vj6svb6+Xqmpqd1uk5qaGlF/9G2cOz3xxBPavHmz3nnnHV133XUDWeaQEOlY//nPf9aRI0eUm5sbagsGg5Kk+Ph4HTp0SBMnThzYomNQX36n09LSNGLECMXFxYXarrnmGvl8PrW1tSkhIWFAa45FfRnndevWacGCBbrnnnskSddee62am5t17733as2aNXI6+fd1f+hpLUxKShqQvSLSEN4zkpCQoJkzZ6q0tDTUFgwGVVpaquzs7G63yc7ODusvSW+//XaP/dG3cZakxx9/XI888ohKSko0a9asaJQa8yId68mTJ+uTTz5RdXV16PKjH/1It912m6qrq5Wenh7N8mNGX36nb7zxRh0+fDgU9iTps88+U1paGkGkB30Z55MnT54XODoDoOFr1vqNlbVwwD4aOwjs2rXLuFwuU1xcbA4cOGDuvfdeM3r0aOPz+YwxxixYsMCsWrUq1P8Pf/iDiY+PN0888YQ5ePCgKSgo4NTeXoh0nDdv3mwSEhLMq6++aurq6kKXpqYmWz9CzIh0rM/F2TS9E+k4Hz161CQmJprly5ebQ4cOmd/97ncmJSXFPProo7Z+hJgQ6TgXFBSYxMRE8+///u+mpqbG/P73vzcTJ040P/7xj239CDGhqanJ7Nu3z+zbt89IMlu2bDH79u0zn3/+uTHGmFWrVpkFCxaE+nee2vsv//Iv5uDBg6aoqIhTey/VU089Zb7xjW+YhIQEk5mZaf7zP/8zdN8tt9xiFi1aFNb/N7/5jZk0aZJJSEgw3/nOd8yePXuiXHFsimScv/nNbxpJ510KCgqiX3gMivR3uivCSO9FOs4fffSRycrKMi6Xy0yYMMH84he/MKdPn45y1bEnknFub283GzZsMBMnTjRut9ukp6eb+++/3/zP//xP9AuPIe+9916377mdY7to0SJzyy23nLfN9OnTTUJCgpkwYYJ5/vnnB7RGhzHs2wIAAPYM2c+MAACA2EAYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYNX/Bx2k2UVTtdA3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75 1.  ]\n",
      " [0.   0.25]\n",
      " [1.   0.75]\n",
      " [0.75 0.  ]\n",
      " [0.   0.75]\n",
      " [1.   0.  ]\n",
      " [0.   0.  ]\n",
      " [1.   0.5 ]\n",
      " [0.   0.5 ]\n",
      " [1.   1.  ]\n",
      " [0.   1.  ]\n",
      " [0.25 1.  ]\n",
      " [0.25 0.  ]\n",
      " [0.5  0.  ]\n",
      " [0.5  1.  ]\n",
      " [1.   0.25]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from dataset_preparing import get_coords_from_densifing_points\n",
    "from dataloader_cocostyle import gdf_to_nodes_and_edges\n",
    "\n",
    "# shapes and dtypes of nodes/edges are exactly same as what I defined in InriaDataLoader\n",
    "\n",
    "original_polygon = Polygon([(0, 0), (100, 0), (100, 100), (0, 100)])\n",
    "# original_polygon = Polygon([(10, 10), (90, 10), (90, 90), (10, 90)])\n",
    "gdf = gpd.GeoDataFrame(geometry = [original_polygon])\n",
    "\n",
    "coords, gdf = get_coords_from_densifing_points(gdf, gap_distance=25)\n",
    "nodes, edges = gdf_to_nodes_and_edges(gdf)\n",
    "nodes = nodes / 100\n",
    "\n",
    "nodes = nodes.astype('float32')\n",
    "edges = np.array(edges).astype('int64')\n",
    "\n",
    "\n",
    "# Visualizer\n",
    "plt.scatter(nodes[:,1], nodes[:,0])\n",
    "for e in edges:\n",
    "    plt.plot(nodes[e,1], nodes[e,0])\n",
    "\n",
    "plt.show()\n",
    "generate_directed_adjacency_matrix(edges)\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'edges'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m output \u001b[38;5;241m=\u001b[39m { \u001b[38;5;66;03m# K개의 샘플링 뽑는 걸로 수정하기\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_nodes\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m, K, \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     11\u001b[0m     } \u001b[38;5;66;03m# x_cord, y_cord\u001b[39;00m\n\u001b[1;32m     12\u001b[0m target \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m'\u001b[39m:[torch\u001b[38;5;241m.\u001b[39mtensor(nodes)]}\n\u001b[0;32m---> 13\u001b[0m out, mask \u001b[38;5;241m=\u001b[39m \u001b[43mmatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nas/tsgil/relationformer/models/DGS.py:129\u001b[0m, in \u001b[0;36mHungarianMatcher.forward\u001b[0;34m(self, outputs, targets, config)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(bs):\n\u001b[1;32m    128\u001b[0m     mapping \u001b[38;5;241m=\u001b[39m {j:i \u001b[38;5;28;01mfor\u001b[39;00m i,j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(indices[b][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),indices[b][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())} \u001b[38;5;66;03m# gt_idx: pred_idx\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     edges \u001b[38;5;241m=\u001b[39m \u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43medges\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[b]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    130\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(edges) \u001b[38;5;66;03m# number of gt_nodes\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     sample_edge \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyError\u001b[0m: 'edges'"
     ]
    }
   ],
   "source": [
    "from models.DGS import HungarianMatcher\n",
    "import torch\n",
    "\n",
    "N = len(nodes)\n",
    "K = 50\n",
    "\n",
    "matcher = HungarianMatcher()\n",
    "matcher.eval()\n",
    "output = { # K개의 샘플링 뽑는 걸로 수정하기\n",
    "    \"pred_nodes\": torch.rand(1, K, 2),\n",
    "    } # x_cord, y_cord\n",
    "target = {'nodes':[torch.tensor(nodes)]}\n",
    "out, mask = matcher(output, target)\n",
    "print(out[0][0])\n",
    "print(out[0][1])\n",
    "mapping = {j:i for i,j in zip(out[0][0].tolist(),out[0][1].tolist())}\n",
    "print(mapping)\n",
    "gt = [nodes[node] for node in out[0][1]]\n",
    "sample = output['pred_nodes'][0]\n",
    "print(gt)\n",
    "print(sample)\n",
    "print(nodes[0],nodes[9])\n",
    "print(edges)\n",
    "plt.scatter(sample[:,1], sample[:,0])\n",
    "if K<N:\n",
    "    mapping2 = {edge[0]: edge[1] for edge in edges}\n",
    "    sample_edge = []\n",
    "    for i, j in edges:\n",
    "        if i not in mapping:\n",
    "            while i not in mapping:\n",
    "                i = mapping2[i]\n",
    "        if j not in mapping:\n",
    "            while j not in mapping:\n",
    "                j = mapping2[j]\n",
    "        if mapping[i] != mapping[j]:\n",
    "            sample_edge.append([mapping[i],mapping[j]])\n",
    "else:\n",
    "    sample_edge = [[mapping[i],mapping[j]] for i, j in edges]\n",
    "for e in sample_edge:\n",
    "    plt.plot(sample[e,1], sample[e,0])\n",
    "plt.show()\n",
    "print(generate_directed_adjacency_matrix(sample_edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 간단한 모델 파라미터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Example model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 20), # 10->20, 파라미터 20*10개\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10) # 20->10, 파라미터 10*20개\n",
    ")\n",
    "\n",
    "# Print the weights of the first linear layer\n",
    "for name, param in model.named_parameters():\n",
    "    if name == '0.weight':  # '0' refers to the first layer\n",
    "        print(param)\n",
    "a = model.state_dict()\n",
    "print(a.keys())\n",
    "a['2.weight'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TopDiG 모델 파라미터와 ckp 파일 파라미터 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import json\n",
    "from models.TopDiG import build_TopDiG\n",
    "from models.backbone_R2U_Net import build_backbone\n",
    "class obj:\n",
    "    def __init__(self, dict1):\n",
    "        self.__dict__.update(dict1)\n",
    "def dict2obj(dict1):\n",
    "    return json.loads(json.dumps(dict1), object_hook=obj)\n",
    "\n",
    "cp_TopDiG = torch.load('/nas/tsgil/relationformer/work_dirs/TopDiG_train/runs/baseline_TopDiG_train_epoch8_10/models/epochs_8.pth', map_location='cpu')\n",
    "cp_backbone = torch.load('/nas/tsgil/relationformer/work_dirs/R2U_Net_pretrain/runs/baseline_R2U_Net_pretrain_epoch200_5e-6_10/models/epochs_130.pth', map_location='cpu')\n",
    "with open('/nas/tsgil/relationformer/configs/TopDiG_train.yaml') as f:\n",
    "    config1 = yaml.load(f, Loader=yaml.FullLoader)\n",
    "config1 = dict2obj(config1)\n",
    "with open('/nas/tsgil/relationformer/configs/inria_pretrain.yaml') as f:\n",
    "    config2 = yaml.load(f, Loader=yaml.FullLoader)\n",
    "config2 = dict2obj(config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cp_backbone.keys())\n",
    "print(cp_backbone['model_state_dict'].keys())\n",
    "# print(cp_backbone['model_state_dict']['encoder.RRCNN1.RCNN.0.conv.0.weight'])\n",
    "\n",
    "model1 = build_TopDiG(config1)\n",
    "model2 = build_backbone(config2)\n",
    "\n",
    "model1_dict = model1.state_dict()\n",
    "model1_backbone_dict = model1.backbone.state_dict()\n",
    "print(model1_dict.keys())\n",
    "print(model1_backbone_dict.keys())\n",
    "total_params = sum(p.numel() for p in model1.backbone.parameters())\n",
    "print(total_params)\n",
    "\n",
    "model2_dict = model2.state_dict()\n",
    "print(model2_dict.keys())\n",
    "model2.load_state_dict(cp_backbone['model_state_dict']) # , strict=False\n",
    "total_params = sum(p.numel() for p in model2.parameters())\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model1_dict.keys()), model1_dict.keys())\n",
    "print(len(model2_dict.keys()), model2_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.equal(model1_backbone_dict['encoder.RRCNN1.RCNN.0.conv.0.weight'], model2_dict['encoder.RRCNN1.RCNN.0.conv.0.weight']):\n",
    "    print('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_name_keywords(name, name_keywords):\n",
    "    for keyword in name_keywords:\n",
    "        if keyword == name.split('.')[0]:\n",
    "            return True\n",
    "    else: return False\n",
    "\n",
    "cnt = 0\n",
    "for n, p in model2.named_parameters():\n",
    "    if match_name_keywords(n, ['encoder']):\n",
    "        cnt += 1\n",
    "print(cnt)\n",
    "cnt = 0\n",
    "for i in model2.parameters():\n",
    "    cnt += 1\n",
    "print(cnt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
